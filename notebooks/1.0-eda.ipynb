{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cf905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 10 Academy - Credit Risk Modeling - Week 5\n",
    "# Task 2: Exploratory Data Analysis (EDA)\n",
    "#\n",
    "# This notebook is for exploratory analysis only and is not for production code.\n",
    "# The goal is to explore the dataset to uncover patterns, identify data\n",
    "# quality issues, and form hypotheses to guide feature engineering.\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Setup: Importing Libraries and Loading Data ---\n",
    "\n",
    "# Import necessary libraries for data manipulation, analysis, and visualization.\n",
    "# pandas: For data loading and manipulation (e.g., creating DataFrames).\n",
    "# matplotlib.pyplot: The primary plotting library for creating static, animated, and interactive visualizations.\n",
    "# seaborn: A high-level interface for drawing attractive and informative statistical graphics, built on top of matplotlib.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style for seaborn to make plots more aesthetically pleasing.\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Load the dataset into a pandas DataFrame.\n",
    "# It's assumed the data file 'data.csv' is in the 'data/raw/' directory.\n",
    "# We use a try-except block to handle potential FileNotFoundError gracefully.\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/data.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The data file was not found. Please ensure 'data.csv' is in the 'data/raw/' directory.\")\n",
    "    # Exit or handle the error as appropriate for a notebook. For now, we'll stop execution.\n",
    "    # In a real script, you might raise the exception.\n",
    "    df = None\n",
    "\n",
    "# --- 2. Overview of the Data ---\n",
    "# Understand the basic structure of the dataset: number of rows, columns, and data types.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 2.1 Overview of the Data ---\")\n",
    "\n",
    "    # Display the total number of rows and columns.\n",
    "    # .shape returns a tuple (number_of_rows, number_of_columns).\n",
    "    print(f\"The dataset has {df.shape[0]} rows (transactions) and {df.shape[1]} columns (features).\")\n",
    "\n",
    "    # Display a concise summary of the DataFrame.\n",
    "    # .info() provides key information:\n",
    "    # - The data type of each column (e.g., object for text, int64 for integers, float64 for decimals).\n",
    "    # - The number of non-null values for each column, which is a first look at missing data.\n",
    "    # - Memory usage of the DataFrame.\n",
    "    print(\"\\nData types and non-null values for each column:\")\n",
    "    df.info()\n",
    "\n",
    "    # Display the first 5 rows to get a feel for the data.\n",
    "    # .head() is useful for a quick inspection of the column values.\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "\n",
    "# --- 3. Summary Statistics ---\n",
    "# Understand the central tendency, dispersion, and shape of the datasetâ€™s distribution.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 3.1 Summary Statistics for Numerical Features ---\")\n",
    "    # .describe() computes summary statistics for numerical columns by default.\n",
    "    # - count: Number of non-null observations.\n",
    "    # - mean: The average value.\n",
    "    # - std: Standard deviation, a measure of data dispersion.\n",
    "    # - min, 25%, 50%, 75%, max: Quartiles that give insight into the distribution. The 50th percentile is the median.\n",
    "    # The large difference between the 75th percentile and the max value for 'Amount' and 'Value' suggests the presence of outliers.\n",
    "    print(df.describe())\n",
    "\n",
    "    print(\"\\n--- 3.2 Summary Statistics for Categorical Features ---\")\n",
    "    # To get statistics for categorical (object type) columns, we use describe(include='object').\n",
    "    # - count: Number of non-null observations.\n",
    "    # - unique: Number of unique categories.\n",
    "    # - top: The most frequently occurring category.\n",
    "    # - freq: The frequency of the 'top' category.\n",
    "    print(df.describe(include='object'))\n",
    "\n",
    "\n",
    "# --- 4. Distribution of Numerical Features ---\n",
    "# Visualize distributions to identify patterns, skewness, and potential outliers.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 4.1 Distribution of Numerical Features ---\")\n",
    "    \n",
    "    # Select numerical columns for visualization. We exclude ID columns and 'FraudResult'.\n",
    "    numerical_features = ['Amount', 'Value']\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, feature in enumerate(numerical_features):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        sns.histplot(df[feature], kde=True, bins=50)\n",
    "        plt.title(f'Distribution of {feature}', fontsize=14)\n",
    "        plt.xlabel(feature, fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.suptitle('Histograms of Key Numerical Features', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Insight: Both 'Amount' and 'Value' are heavily right-skewed.\n",
    "    # This means most transactions are for small amounts, with a few very large transactions.\n",
    "    # This skewness might require transformation (e.g., log transformation) before modeling.\n",
    "\n",
    "\n",
    "# --- 5. Distribution of Categorical Features ---\n",
    "# Analyze the frequency and variability of categories.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 5.1 Distribution of Categorical Features ---\")\n",
    "\n",
    "    # Select key categorical columns for visualization.\n",
    "    categorical_features = ['ProductCategory', 'ChannelId', 'ProviderId']\n",
    "\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    for i, feature in enumerate(categorical_features):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        # We take the top 10 most frequent categories for clarity, especially for 'ProviderId'.\n",
    "        top_categories = df[feature].value_counts().nlargest(10).index\n",
    "        sns.countplot(y=feature, data=df, order=top_categories, palette='viridis')\n",
    "        plt.title(f'Top 10 Distribution of {feature}', fontsize=14)\n",
    "        plt.xlabel('Count', fontsize=12)\n",
    "        plt.ylabel(feature, fontsize=12)\n",
    "    plt.suptitle('Bar Plots of Key Categorical Features', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Insight:\n",
    "    # - ProductCategory: 'airtime' and 'financial_services' are the most common product categories.\n",
    "    # - ChannelId: 'ChannelId_3' is the dominant channel. Understanding what this channel is (e.g., Android, iOS, Web) would be important.\n",
    "    # - ProviderId: 'ProviderId_4' and 'ProviderId_6' are the most used providers. The distribution is quite concentrated.\n",
    "\n",
    "\n",
    "# --- 6. Correlation Analysis ---\n",
    "# Understand the linear relationship between numerical features.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 6.1 Correlation Analysis ---\")\n",
    "    \n",
    "    # Calculate the correlation matrix for numerical features.\n",
    "    # .corr() computes pairwise correlation of columns.\n",
    "    # We only have a few numerical columns, but this is a standard step.\n",
    "    # After feature engineering, this analysis will be more insightful.\n",
    "    correlation_matrix = df[['Amount', 'Value', 'FraudResult']].corr()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Correlation Matrix of Numerical Features', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # Insight:\n",
    "    # - 'Amount' and 'Value' have a correlation of 0.81, which is expected since Value is the absolute of Amount.\n",
    "    # - 'FraudResult' has a very weak linear correlation with 'Amount' and 'Value'.\n",
    "    # This suggests that a simple linear model based only on these features might not perform well.\n",
    "    # Non-linear models or more engineered features will be necessary.\n",
    "\n",
    "\n",
    "# --- 7. Identifying Missing Values ---\n",
    "# Identify missing data to decide on appropriate imputation strategies.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 7.1 Identifying Missing Values ---\")\n",
    "\n",
    "    # Calculate the number of missing values in each column.\n",
    "    missing_values = df.isnull().sum()\n",
    "    \n",
    "    # Calculate the percentage of missing values.\n",
    "    missing_percentage = (missing_values / len(df)) * 100\n",
    "    \n",
    "    # Create a DataFrame to display missing value counts and percentages.\n",
    "    missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_percentage})\n",
    "    \n",
    "    # Display columns with missing values, sorted by percentage.\n",
    "    print(missing_info[missing_info['Missing Values'] > 0].sort_values(by='Percentage (%)', ascending=False))\n",
    "\n",
    "    # Visualize missing values with a heatmap.\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "    plt.title('Heatmap of Missing Values', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # Insight: There are no missing values in this dataset.\n",
    "    # This simplifies the data preprocessing step, as no imputation is needed.\n",
    "\n",
    "\n",
    "# --- 8. Outlier Detection ---\n",
    "# Use box plots to identify potential outliers in numerical data.\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\n--- 8.1 Outlier Detection ---\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, feature in enumerate(numerical_features):\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        sns.boxplot(y=df[feature], color='skyblue')\n",
    "        plt.title(f'Box Plot of {feature}', fontsize=14)\n",
    "        plt.ylabel(feature, fontsize=12)\n",
    "    plt.suptitle('Box Plots for Outlier Detection', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Insight:\n",
    "    # The box plots confirm the presence of a large number of outliers for both 'Amount' and 'Value'.\n",
    "    # The points far above the main box represent transactions with unusually high values.\n",
    "    # These outliers could be legitimate high-value transactions, or they could be fraudulent.\n",
    "    # Their impact on the model needs to be considered.\n",
    "    # Techniques like scaling (StandardScaler, RobustScaler) or transformations can help mitigate their effect.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
